import { GoogleGenerativeAI } from '@google/generative-ai'
import { expect, test } from 'vitest'

const API_KEY = process.env.GEMINI_API_KEY
const genAI = new GoogleGenerativeAI(API_KEY || '')
const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' })

// LLM ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æŠ•ã’ã€æ¶ˆè²»ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã‚‚å–å¾—
async function getLLMResponse(
  prompt: string,
): Promise<{ text: string; promptTokenCount: number; candidatesTokenCount: number }> {
  console.log(`ğŸš€ æŠ•ã’ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: \n"${prompt}"\n`)

  const response = await model.generateContent(prompt)
  const promptTokenCount = response.response.usageMetadata?.promptTokenCount ?? 0
  const candidatesTokenCount = response.response.usageMetadata?.candidatesTokenCount ?? 0
  const text = response.response.text()

  console.log(`âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‡¦ç† - å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: ${promptTokenCount}, å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: ${candidatesTokenCount}`)
  console.log(`   â–¶ï¸  å‡ºåŠ›: "${text}"\n`)

  return { text, promptTokenCount, candidatesTokenCount }
}

// LLM ã«è©•ä¾¡ã‚’ã•ã›ã€æ¶ˆè²»ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã‚‚å–å¾—
async function evaluateElementPresence(
  response: string,
  element: string,
  shouldInclude: boolean,
): Promise<{ isCorrect: boolean; promptTokenCount: number; candidatesTokenCount: number }> {
  const evalPrompt = `
  ä»¥ä¸‹ã®æ–‡ç« ã« "${element}" ã¨ã„ã†è¦ç´ ãŒ **å«ã¾ã‚Œã¦ã„ã‚Œã°"YES",å«ã¾ã‚Œã¦ã„ãªã‘ã‚Œã°"NO"ã¨ç­”ãˆã¦ãã ã•ã„**

  æ–‡ç« ã¯ä»¥ä¸‹ã§ã™
  -----
  ${response}
  -----
  æ–‡ç« ã¯ä»¥ä¸Šã§ã™
  `

  console.log(`ğŸš€ æŠ•ã’ã‚‹è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: \n"${evalPrompt}"\n`)

  const evalResponse = await model.generateContent(evalPrompt)
  const promptTokenCount = evalResponse.response.usageMetadata?.promptTokenCount ?? 0
  const candidatesTokenCount = evalResponse.response.usageMetadata?.candidatesTokenCount ?? 0
  const answer = evalResponse.response.text().trim().toUpperCase()
  const isCorrect = (shouldInclude && answer.includes('YES')) || (!shouldInclude && answer.includes('NO'))

  console.log(`âœ… è©•ä¾¡å‡¦ç† - è¦ç´ : "${element}"`)
  console.log(`   â–¶ï¸  å‡ºåŠ›: "${evalResponse.response.text()}"`)
  console.log(`   ğŸ”¹ åˆ¤å®š: ${isCorrect ? 'âœ… æ­£ã—ã„' : 'âŒ èª¤ã‚Š'}`)
  console.log(`   ğŸ”¢ æ¶ˆè²»ãƒˆãƒ¼ã‚¯ãƒ³: å…¥åŠ›=${promptTokenCount}, å‡ºåŠ›=${candidatesTokenCount}\n`)

  return { isCorrect, promptTokenCount, candidatesTokenCount }
}

// ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
test('Gemini ã®å¿œç­”ã«æœŸå¾…ã™ã‚‹è¦ç´ ãŒå«ã¾ã‚Œã‚‹ã‹ã‚’ LLM ã«è©•ä¾¡ã•ã›ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨˜éŒ²', async () => {
  const userPrompt = 'æ—¥æœ¬ã®æ¼«ç”»å®¶ã®è—¤æœ¬ã‚¿ãƒ„ã‚­ã®ä»£è¡¨ä½œã‚’4å€‹æŒ™ã’ã¦'

  // 1å›ç›®: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‡¦ç†
  const { text: response, promptTokenCount: promptTokens1, candidatesTokenCount: candidatesTokens1 } =
    await getLLMResponse(userPrompt)

  // 2å›ç›®: è©•ä¾¡å‡¦ç†
  const expectedIncludedElements = ['ãƒã‚§ãƒ³ã‚½ãƒ¼ãƒãƒ³', 'ãƒ«ãƒƒã‚¯ãƒãƒƒã‚¯'] // ã“ã‚Œã‚‰ãŒå«ã¾ã‚Œã‚‹ã¹ã
  const expectedExcludedElements = ['ã¿ã©ã‚Šã®ãƒã‚­ãƒã‚ªãƒ¼', 'åŒ—æ–—ã®æ‹³'] // ã“ã‚Œã‚‰ã¯å«ã¾ã‚Œã¦ã¯ã„ã‘ãªã„

  let totalPromptTokens = promptTokens1
  let totalCandidatesTokens = candidatesTokens1

  for (const element of expectedIncludedElements) {
    const { isCorrect, promptTokenCount, candidatesTokenCount } = await evaluateElementPresence(response, element, true)
    expect(isCorrect).toBe(true)
    totalPromptTokens += promptTokenCount
    totalCandidatesTokens += candidatesTokenCount
  }

  for (const element of expectedExcludedElements) {
    const { isCorrect, promptTokenCount, candidatesTokenCount } = await evaluateElementPresence(response, element, false)
    expect(isCorrect).toBe(true)
    totalPromptTokens += promptTokenCount
    totalCandidatesTokens += candidatesTokenCount
  }

  // ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®åˆè¨ˆã‚’ãƒ­ã‚°å‡ºåŠ›
  console.log(`âœ… 1å›ç›®ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‡¦ç†ï¼‰æ¶ˆè²»ãƒˆãƒ¼ã‚¯ãƒ³: å…¥åŠ›=${promptTokens1}, å‡ºåŠ›=${candidatesTokens1}`)
  console.log(`âœ… 2å›ç›®ï¼ˆè©•ä¾¡å‡¦ç†ï¼‰åˆè¨ˆæ¶ˆè²»ãƒˆãƒ¼ã‚¯ãƒ³: å…¥åŠ›=${totalPromptTokens - promptTokens1}, å‡ºåŠ›=${totalCandidatesTokens - candidatesTokens1}`)
  console.log(`âœ… ç·æ¶ˆè²»ãƒˆãƒ¼ã‚¯ãƒ³: ${totalPromptTokens + totalCandidatesTokens}\n`)
}, 100000)
